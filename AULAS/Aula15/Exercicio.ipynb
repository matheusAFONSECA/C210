{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício: Adaline e Perceptron\n",
    "\n",
    "\n",
    "Dado os seguintes dados de treinamento, onde o valor entre parênteses é a coordenada e o \"1\" ou \"-1\" é a resposta desejada:\n",
    "\n",
    "    (-0.67, 0.51), 1\n",
    "    (1.13, 1.34), 1\n",
    "    (-0.63, -0.02), 1\n",
    "    (0.10, -1.35), -1\n",
    "    (0.88, -1.09), -1\n",
    "    (0.94, 0.61), -1\n",
    "    (-1.06, -1.13), -1\n",
    "    (-0.85, -0.34), 1\n",
    "    (-0.38, -0.29), 1\n",
    "    (0.18, -0.72), -1\n",
    "    (0.24, -0.08), 1\n",
    "    (-0.80, -0.31), 1\n",
    "    (0.25, 0.36), 1\n",
    "    (-1.19, -0.61), 1\n",
    "    (0.78, 1.05), 1\n",
    "    (0.46, -0.19), -1\n",
    "    (-0.12, 0.56), 1\n",
    "    (1.52, 1.69), 1\n",
    "    (0.84, -0.68), -1\n",
    "    (-1.16, -0.73), 1\n",
    "\n",
    "Treine as redes Adaline e Perceptron para resolver esse problema. Depois teste com o seguinte conjunto de dados:\n",
    "\n",
    "    (-0.91, 1.26), 1\n",
    "    (-1.06, 1.20), 1\n",
    "    (0.16, 0.80), 1\n",
    "    (-1.07, 1.82), 1\n",
    "    (0.07, 0.12), 1\n",
    "    (1.33, -0.13), -1\n",
    "\n",
    "\n",
    "Dica: Use  $η=0.01$ nos dois, 1000 épocas no perceptron e um critério de parada de $10^-3$ (1e-3) no Adaline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código Adaline (não precisa alterar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline:\n",
    "    \n",
    "    def __init__(self, lr, e):\n",
    "        '''Construtor, define taxa de aprendizado e a taxa de erro aceita para convergir'''\n",
    "        self.lr = lr\n",
    "        self.e = e\n",
    "    def activation(self, value):\n",
    "        ''' 1 se value > 0, -1 senão'''\n",
    "        return (1 if value >= 0 else -1)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        ''' Multiplicação matricial entre as entradas e os pesos somado ao bias proporcional'''\n",
    "        return np.dot(x, self.weights.T) + self.bias * self.w_bias\n",
    "    \n",
    "    def evaluate(self, target, predicted):\n",
    "        ''' Calcula a diferença entre o valor real e o valor predito'''\n",
    "        return (target - predicted)\n",
    "    \n",
    "    def train(self, x, d):\n",
    "        ''' Definir aleatoriamente os pesos, o bias e o peso do bias\n",
    "            Enquanto a diferença entre m mse_anterior e o mse_atual for maior que 'e' continua o processo \n",
    "        '''\n",
    "        self.weights = np.random.random(x.shape[1])\n",
    "        self.bias = -1\n",
    "        self.w_bias = np.random.random()\n",
    "        \n",
    "        epoch = 0\n",
    "        self.total_mse = []\n",
    "        last_mse = np.inf\n",
    "        \n",
    "        \n",
    "        while True:\n",
    "            mse = 0\n",
    "            # Para cada amostra\n",
    "            for xi, target in zip(x, d):\n",
    "                \n",
    "                predicted = self.predict(xi)  \n",
    "                current_error = self.evaluate(target, predicted)\n",
    "                mse += (current_error ** 2)\n",
    "                self.weights += self.lr * current_error * xi\n",
    "                self.w_bias += self.lr * current_error * self.bias\n",
    "                \n",
    "            mse = (mse/len(x))\n",
    "            print(f\"EPOCH: {epoch}\\t- MSE: {mse}\\t- MSE_ant - MSE: {abs(last_mse - mse)}\")\n",
    "            if abs(last_mse - mse) <= self.e:\n",
    "                break\n",
    "            \n",
    "            self.total_mse.append(mse)\n",
    "            last_mse = mse\n",
    "            epoch +=1\n",
    "            \n",
    "    def test(self, x):\n",
    "        ''' Dado uma lista de X, submete-os à rede'''\n",
    "        results = []\n",
    "        for xi in x:\n",
    "            predict = self.predict(xi)\n",
    "            predict = self.activation(predict)\n",
    "            results.append(predict)\n",
    "            \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código Perceptron (não precisa alterar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, lr, n_epochs):\n",
    "        '''Construtor, define taxa de aprendizado e número máximo de épocas'''\n",
    "        self.lr = lr\n",
    "        self.n_epochs = n_epochs\n",
    "        \n",
    "    def activation(self, value):\n",
    "        ''' 1 se value > 0, -1 se value < 0, 0 se value == 0 '''\n",
    "        return (1 if value > 0 else -1 if value < 0 else 0)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        ''' Multiplicação matricial entre as entradas e os pesos somado ao bias proporcional'''\n",
    "        return np.dot(x, self.weights.T) + self.bias * self.w_bias\n",
    "    \n",
    "    def evaluate(self, target, predicted):\n",
    "        ''' Calcula a diferença entre o valor real e o valor predito'''\n",
    "        return (target - predicted)\n",
    "    \n",
    "    def train(self, x, d):\n",
    "        ''' Definir aleatoriamente os pesos, o bias e o peso do bias\n",
    "            Enquanto houver erro, ou o máximo de épocas não for atingido continua o processo\n",
    "            \n",
    "        '''\n",
    "        self.weights = np.random.random(x.shape[1])\n",
    "        self.bias = np.random.random()\n",
    "        self.w_bias = np.random.random()\n",
    "        \n",
    "        epoch = 0\n",
    "        is_error = True\n",
    "        self.total_error = []\n",
    "        \n",
    "        while is_error and epoch < self.n_epochs:\n",
    "            \n",
    "            is_error  = False\n",
    "            epoch_errors = 0\n",
    "            \n",
    "            # Para cada amostra\n",
    "            for xi, target in zip(x, d):\n",
    "                \n",
    "                predicted = self.predict(xi)\n",
    "                predicted = self.activation(predicted)\n",
    "                \n",
    "                current_error = self.evaluate(target, predicted)\n",
    "                epoch_errors += current_error\n",
    "                \n",
    "                # Se houve erro, atualizar os pesos\n",
    "                if predicted != target:\n",
    "                    \n",
    "                    self.weights += self.lr * current_error * xi\n",
    "                    self.w_bias += self.lr * current_error * self.bias\n",
    "                    is_error = True\n",
    "                    \n",
    "            self.total_error.append(epoch_errors/len(x))\n",
    "            epoch += 1\n",
    "            \n",
    "    def test(self, x):\n",
    "        ''' Dado uma lista de X, submete-os à rede'''\n",
    "        results = []\n",
    "        for xi in x:\n",
    "            predict = self.predict(xi)\n",
    "            predict = self.activation(predict)\n",
    "            results.append(predict)\n",
    "            \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
